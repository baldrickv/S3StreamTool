Copyright (c) 2010 baldrickv

Purpose:

  The purpose of this tool is to allow for streaming data of very large or 
  unknown size into and out of S3 using multi-part upload and ranged downloaded 
  respectively.  There is some deduplication code, which works but isn't built 
  into the streaming yet.


Use:

  To use as a library, do "ant jar" and use "jar/S3StreamingTool.jar".  It does 
  not include libraries it depends on.  You can probably just drop it and whatever 
  dependancies you don't already have into your build setup.

  To use as a command line tool do "ant jar" and use "jar/S3Download.jar" and 
  "jar/S3Upload.jar".  They are self-contained and have all their dependancies 
  built in. The command line should look like:

  cat /dev/hda1 | 
   java -jar S3Upload.jar my_bucket my_new_streaming_file 10485760 /path/to/aes.key /path/to/aws.creds

  The number there is the block size.  Due to S3 limitations, your total stream 
  file is limited to your block size times 10000.  So with a 10mb block size, 
  you can stream up to 97.6GB.  If you want to go to the S3 max of 5TB, you'll 
  need to use a block size of around 500MB.  Note: each block needs to be able 
  to fit into memory at least twice.  So if using a large block size, adjust 
  -Xmx up accordingly.

  Using a smaller block size means less data in memory at once and less that 
  has to be retried in the event of errors.

  The download command line is very similar:
  java -jar S3Download.jar my_bucket my_streaming_file 10485760 /path/to/aes.key /path/to/aws.creds 
    > /path/to/output

  The blocksize used by the download does not need to be the same as the upload.  
  Also, there is no limitation on number of blocks downloaded.  If you want to 
  download 5TB at 16 bytes each request, go right ahead.

  Note: if the block size is set to less than the key size, it will be set to 
  the key size.  This avoid some nasty code.

  The aes.key is expected to be a 16 (128-bit) or 32 (256-bit) byte file that 
  is simply an AES key.  If you need a new one, you can use /dev/random to make 
  one.  (dd if=/dev/random of=aes.key bs=1 count=16).

  Note: using a 256-bit key might require enabling unlimited strength crypto in 
  your JVM.

  The aws.creds file is expected to be your aws key id and aws secret key 
  separated by whitespace.
  So as an example: 

  ABCDEFGHIJKLMNOPQRST KbDygrNynV/ok1MuiD46Rkw0hH6LRHHZePhdOeeqEHo

  These commands lines are of course a pain, so I recommend making a shell 
  script around them that knows the location of your keys and credentails.

Encryption:

  The encryption is done using AES 128 or 256 using mode "AES/CBC/PKCS5PADDING".
  The initialization vector (IV) is random and prepended to the start of each file.
  With the IV and padding, the stored file in S3 will be larger than
  the input file by at most two times the AES key size.

Errors:
  
  These tools are coded to be very resilient.  If there are errors they just 
  retry (with a 5 second pause) until they succeed.  This way, a network outage
  in the middle of a multi-GB stream will not abort the entire process.

Cleanup:

  If a streaing upload is interupted there will be left-over partial upload 
  files in your S3 bucket.

  They will not be visible in the AWS Console (at least currently).  They 
  should be cleaned up or you will continue to pay for them.  This tool doesn't 
  do that yet.

Libraries:

  To get the latest, go to http://aws.amazon.com/sdkforjava/, download the 
  latest and put all its jars in 'libs'.

  As of this writing those are:

    aws-java-sdk-1.1.0.jar
    commons-codec-1.3.jar
    commons-httpclient-3.0.1.jar
    commons-logging-1.1.1.jar
    jackson-core-asl-1.4.3.jar
    junit-4.8.2.jar
    stax-1.2.0.jar
    stax-api-1.0.1.jar

Testing:

  The junit tests written a test all the way to S3.  So they need a bucket and 
  credentials.  To be able to run "ant test" populate "s3streamtest.txt" with 
  your data.  The tests write and read about 100mb so it can take some time.


Todo:
  
  Make output and logging consistent so that it is suitable to use in a libary
  or situation where no non-error output is desired.

  Add multi-part upload cleanup.

  Figure out how to display javadocs in github.



